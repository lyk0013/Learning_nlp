{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "congressional-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import pad_mask, subsequence_mask\n",
    "from utils import PositionalEncoding, EncoderLayer, DecoderLayer\n",
    "from utils import TransformerDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "crucial-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomData:\n",
    "    def __init__(self):\n",
    "        self.src_vocab = {'P' : 0, 'ich' : 1, 'mochte' : 2, 'ein' : 3, 'bier' : 4, 'cola' : 5}\n",
    "        self.src_vocab_size = len(self.src_vocab)\n",
    "        self.src_idx2word = {i: w for i, w in enumerate(self.src_vocab)}\n",
    "\n",
    "        self.tgt_vocab = {'P' : 0, 'i' : 1, 'want' : 2, 'a' : 3, 'beer' : 4, 'coke' : 5, 'S' : 6, 'E' : 7, '.' : 8}\n",
    "        self.tgt_idx2word = {i: w for i, w in enumerate(self.tgt_vocab)}\n",
    "        self.tgt_vocab_size = len(self.tgt_vocab)\n",
    "        \n",
    "    def make_data(self, sentences):\n",
    "        enc_inputs, dec_inputs, dec_outputs = [], [], []\n",
    "        for i in range(len(sentences)):\n",
    "            enc_input = [[self.src_vocab[n] for n in sentences[i][0].split()]]\n",
    "            dec_input = [[self.tgt_vocab[n] for n in sentences[i][1].split()]]        \n",
    "            dec_output = [[self.tgt_vocab[n] for n in sentences[i][2].split()]]\n",
    "\n",
    "            enc_inputs.extend(enc_input)\n",
    "            dec_inputs.extend(dec_input)\n",
    "            dec_outputs.extend(dec_output)\n",
    "\n",
    "        return torch.LongTensor(enc_inputs), torch.LongTensor(dec_inputs), torch.LongTensor(dec_outputs)\n",
    "    \n",
    "    def get_test_data(self, sentences):\n",
    "        return self.make_data(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-motivation",
   "metadata": {},
   "source": [
    "### pytorch.nn.Transformer mask参数解释\n",
    "\n",
    "**\\*_mask: attn_mask(T, T), 为了在decoder中屏蔽未来的词**  \n",
    "**\\*_key_padding_mask: pad_mask(B, S/T), 避免PAD填充项参与运算**   \n",
    "**另外，在最后计算loss的时候，也要指定ignoreindex=pad_idx**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-flexibility",
   "metadata": {},
   "source": [
    "### pytorch.nn.Transformer 是没有实现Positional Encoding的，需要自己实现 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ongoing-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等同于 nn.Transformer.generate_square_subsequent_mask\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz))) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pending-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(X_encoder, X_decoder):\n",
    "    encoder_sequence_len = X_encoder.shape[1]\n",
    "    decoder_sequence_len = X_decoder.shape[1]\n",
    "    \n",
    "    decoder_sub_sequence_mask = generate_square_subsequent_mask(decoder_sequence_len)\n",
    "    encoder_sub_sequence_mask = torch.zeros((encoder_sequence_len, encoder_sequence_len)).type(torch.bool)\n",
    "    \n",
    "    encoder_padding_mask = (X_encoder == PAD_IDX)\n",
    "    decoder_padding_mask = (X_decoder == PAD_IDX)\n",
    "    return encoder_sub_sequence_mask, decoder_sub_sequence_mask, encoder_padding_mask, decoder_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "overhead-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, encoder_vocab_size, decoder_vocab_size, \n",
    "                 embedding_size, n_heads, hidden_size, num_encoder_layers, num_decoder_layers, dropout=0.1,\n",
    "                 batch_first=True\n",
    "                ):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=embedding_size,\n",
    "            nhead=n_heads,\n",
    "            num_encoder_layers= num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=hidden_size,\n",
    "            dropout=dropout,\n",
    "            batch_first=batch_first\n",
    "        )\n",
    "        self.linear = nn.Linear(embedding_size, decoder_vocab_size)\n",
    "        self.encoder_embedding = nn.Embedding(encoder_vocab_size, embedding_size)\n",
    "        self.decoder_embedding = nn.Embedding(decoder_vocab_size, embedding_size)\n",
    "        self.positional_encoding = PositionalEncoding(embedding_size, dropout=dropout)\n",
    "        \n",
    "    def forward(self, X_encoder, X_decoder, \n",
    "                encoder_mask, decoder_mask, \n",
    "                encoder_key_padding_mask, \n",
    "                decoder_key_padding_mask,\n",
    "                memory_key_padding_mask\n",
    "               ):\n",
    "        # embedding and positional encoding\n",
    "        X_encoder = self.positional_encoding(\n",
    "            self.encoder_embedding(X_encoder)\n",
    "        )\n",
    "        X_decoder = self.positional_encoding(\n",
    "            self.decoder_embedding(X_decoder)\n",
    "        )\n",
    "        # transformer forward\n",
    "        Y = self.transformer(\n",
    "            X_encoder, X_decoder,\n",
    "            encoder_mask, decoder_mask,\n",
    "            None, encoder_key_padding_mask, decoder_key_padding_mask,\n",
    "            memory_key_padding_mask\n",
    "        )\n",
    "        # Y: [batch_size, length_decoder, vocab_decoder_size]\n",
    "        Y = self.linear(Y)\n",
    "        return Y\n",
    "    \n",
    "    def encoder(self, X, mask):\n",
    "        X = self.positional_encoding(\n",
    "            self.encoder_embedding(X)\n",
    "        )\n",
    "        Y = self.transformer.encoder(X, mask)\n",
    "        return Y\n",
    "    \n",
    "    def decoder(self, X, memory, mask):\n",
    "        X = self.positional_encoding(\n",
    "            self.decoder_embedding(X)\n",
    "        )\n",
    "        Y = self.transformer.decoder(X, memory, mask)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-virtue",
   "metadata": {},
   "source": [
    "### 生成测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "artificial-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "        # enc_input           dec_input         dec_output\n",
    "        ['ich mochte ein bier P', 'S i want a beer .', 'i want a beer . E'],\n",
    "        ['ich mochte ein cola P', 'S i want a coke .', 'i want a coke . E']\n",
    "]\n",
    "custom_data = CustomData()\n",
    "enc_inputs, dec_inputs, dec_outputs = custom_data.get_test_data(sentences)\n",
    "dataset = TransformerDataset(enc_inputs, dec_inputs, dec_outputs)\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "minus-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data_loader:\n",
    "    enc_inputs, dec_inputs, dec_outputs = [x for x in batch]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "conscious-compatibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 0],\n",
       "        [1, 2, 3, 5, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-highlight",
   "metadata": {},
   "source": [
    "### 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "handy-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "lr = 1e-4\n",
    "weight_decay =1e-5\n",
    "epochs = 100\n",
    "num_encoder_layers= num_decoder_layers = 6\n",
    "n_heads = 8\n",
    "embedding_size = 512\n",
    "hidden_size = 300\n",
    "dropout = 0.1\n",
    "batch_first=True\n",
    "encoder_vocab_size = custom_data.src_vocab_size\n",
    "decoder_vocab_size = custom_data.tgt_vocab_size\n",
    "\n",
    "PAD_IDX = 0\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-grill",
   "metadata": {},
   "source": [
    "### 初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "hired-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqTransformer(\n",
    "    encoder_vocab_size, decoder_vocab_size,\n",
    "    embedding_size, n_heads, hidden_size, num_encoder_layers, num_decoder_layers, dropout, True\n",
    ")\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=lr, \n",
    "    weight_decay=weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-entity",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "round-drilling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss = 2.342865\n",
      "Epoch: 0002 loss = 1.988479\n",
      "Epoch: 0003 loss = 1.983640\n",
      "Epoch: 0004 loss = 1.990919\n",
      "Epoch: 0005 loss = 1.912256\n",
      "Epoch: 0006 loss = 1.940863\n",
      "Epoch: 0007 loss = 1.961138\n",
      "Epoch: 0008 loss = 1.937107\n",
      "Epoch: 0009 loss = 1.792636\n",
      "Epoch: 0010 loss = 1.867918\n",
      "Epoch: 0011 loss = 1.973863\n",
      "Epoch: 0012 loss = 1.801910\n",
      "Epoch: 0013 loss = 1.827447\n",
      "Epoch: 0014 loss = 1.761702\n",
      "Epoch: 0015 loss = 1.789762\n",
      "Epoch: 0016 loss = 1.654130\n",
      "Epoch: 0017 loss = 1.629984\n",
      "Epoch: 0018 loss = 1.649120\n",
      "Epoch: 0019 loss = 1.677012\n",
      "Epoch: 0020 loss = 1.472674\n",
      "Epoch: 0021 loss = 1.595101\n",
      "Epoch: 0022 loss = 1.534014\n",
      "Epoch: 0023 loss = 1.495038\n",
      "Epoch: 0024 loss = 1.390178\n",
      "Epoch: 0025 loss = 1.299923\n",
      "Epoch: 0026 loss = 1.251586\n",
      "Epoch: 0027 loss = 1.121074\n",
      "Epoch: 0028 loss = 1.097341\n",
      "Epoch: 0029 loss = 1.165710\n",
      "Epoch: 0030 loss = 1.097595\n",
      "Epoch: 0031 loss = 0.904429\n",
      "Epoch: 0032 loss = 0.982850\n",
      "Epoch: 0033 loss = 0.976796\n",
      "Epoch: 0034 loss = 0.692688\n",
      "Epoch: 0035 loss = 0.682223\n",
      "Epoch: 0036 loss = 0.602256\n",
      "Epoch: 0037 loss = 0.624071\n",
      "Epoch: 0038 loss = 0.560937\n",
      "Epoch: 0039 loss = 0.489259\n",
      "Epoch: 0040 loss = 0.488700\n",
      "Epoch: 0041 loss = 0.423414\n",
      "Epoch: 0042 loss = 0.417092\n",
      "Epoch: 0043 loss = 0.376039\n",
      "Epoch: 0044 loss = 0.414244\n",
      "Epoch: 0045 loss = 0.335277\n",
      "Epoch: 0046 loss = 0.249855\n",
      "Epoch: 0047 loss = 0.208787\n",
      "Epoch: 0048 loss = 0.150105\n",
      "Epoch: 0049 loss = 0.181911\n",
      "Epoch: 0050 loss = 0.181454\n",
      "Epoch: 0051 loss = 0.149002\n",
      "Epoch: 0052 loss = 0.113452\n",
      "Epoch: 0053 loss = 0.105577\n",
      "Epoch: 0054 loss = 0.133704\n",
      "Epoch: 0055 loss = 0.096964\n",
      "Epoch: 0056 loss = 0.090068\n",
      "Epoch: 0057 loss = 0.081395\n",
      "Epoch: 0058 loss = 0.081367\n",
      "Epoch: 0059 loss = 0.067005\n",
      "Epoch: 0060 loss = 0.058163\n",
      "Epoch: 0061 loss = 0.068035\n",
      "Epoch: 0062 loss = 0.056132\n",
      "Epoch: 0063 loss = 0.059810\n",
      "Epoch: 0064 loss = 0.046353\n",
      "Epoch: 0065 loss = 0.039799\n",
      "Epoch: 0066 loss = 0.034366\n",
      "Epoch: 0067 loss = 0.043187\n",
      "Epoch: 0068 loss = 0.031601\n",
      "Epoch: 0069 loss = 0.032950\n",
      "Epoch: 0070 loss = 0.031893\n",
      "Epoch: 0071 loss = 0.021912\n",
      "Epoch: 0072 loss = 0.022126\n",
      "Epoch: 0073 loss = 0.033595\n",
      "Epoch: 0074 loss = 0.059534\n",
      "Epoch: 0075 loss = 0.041913\n",
      "Epoch: 0076 loss = 0.022483\n",
      "Epoch: 0077 loss = 0.024229\n",
      "Epoch: 0078 loss = 0.044040\n",
      "Epoch: 0079 loss = 0.038648\n",
      "Epoch: 0080 loss = 0.022221\n",
      "Epoch: 0081 loss = 0.020893\n",
      "Epoch: 0082 loss = 0.014926\n",
      "Epoch: 0083 loss = 0.017876\n",
      "Epoch: 0084 loss = 0.014030\n",
      "Epoch: 0085 loss = 0.013400\n",
      "Epoch: 0086 loss = 0.015689\n",
      "Epoch: 0087 loss = 0.012873\n",
      "Epoch: 0088 loss = 0.013957\n",
      "Epoch: 0089 loss = 0.017114\n",
      "Epoch: 0090 loss = 0.011753\n",
      "Epoch: 0091 loss = 0.014418\n",
      "Epoch: 0092 loss = 0.011518\n",
      "Epoch: 0093 loss = 0.012333\n",
      "Epoch: 0094 loss = 0.008362\n",
      "Epoch: 0095 loss = 0.015575\n",
      "Epoch: 0096 loss = 0.011910\n",
      "Epoch: 0097 loss = 0.014741\n",
      "Epoch: 0098 loss = 0.021049\n",
      "Epoch: 0099 loss = 0.012216\n",
      "Epoch: 0100 loss = 0.009735\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch in data_loader:\n",
    "        enc_inputs, dec_inputs, dec_outputs = [x.to(device) for x in batch]\n",
    "        # mask\n",
    "        encoder_sub_sequence_mask, decoder_sub_sequence_mask, encoder_padding_mask, decoder_padding_mask = create_mask(\n",
    "            enc_inputs, dec_inputs\n",
    "        )\n",
    "        \n",
    "        # outputs: [batch_size, length, vocab_size]\n",
    "        outputs = model(\n",
    "            enc_inputs, dec_inputs, \n",
    "            encoder_sub_sequence_mask, decoder_sub_sequence_mask, encoder_padding_mask, decoder_padding_mask,\n",
    "            encoder_padding_mask\n",
    "        )\n",
    "        l = loss(outputs.transpose(2, 1), dec_outputs)\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(l))\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-confirmation",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "seven-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearch:\n",
    "    def __init__(self, model, k=2, start_symbol=None, stop_symbol=None, max_predict_length=1000):\n",
    "        self.model = model\n",
    "        self.k, self.max_predict_length = k, max_predict_length\n",
    "        self.start_symbol, self.stop_symbol= start_symbol, stop_symbol\n",
    "        \n",
    "    def greedy_decoder(self, X):\n",
    "        X_encoder = X.view(1, -1)\n",
    "        num_tokens = X_encoder.shape[1]\n",
    "        X_encoder_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "        Y_encoder = model.encoder(X_encoder, X_encoder_mask)\n",
    "        \n",
    "        next_word = self.start_symbol\n",
    "        dec_input = torch.zeros(1, 0).type_as(X_encoder.data)\n",
    "        while True:\n",
    "            # concate next word\n",
    "            dec_input = torch.cat([dec_input.detach(),torch.tensor([[next_word]],dtype=X_encoder.dtype)],-1)\n",
    "            # run decoder and linear\n",
    "            tgt_mask = (generate_square_subsequent_mask(dec_input.size(1))\n",
    "                    .type(torch.bool))\n",
    "            Y_decoder = model.decoder(dec_input, Y_encoder, tgt_mask)\n",
    "            word_probability = model.linear(Y_decoder)\n",
    "            word_probability = word_probability.squeeze(0).max(dim=-1, keepdim=False)[1]\n",
    "            next_word = word_probability[-1]\n",
    "            \n",
    "            if next_word in self.stop_symbol or dec_input.size(1)>=self.max_predict_length:\n",
    "                dec_input = torch.cat([dec_input.detach(),torch.tensor([[next_word]],dtype=X_encoder.dtype)],-1)\n",
    "                return dec_input.squeeze(0)\n",
    "    \n",
    "    def search(self, X):\n",
    "        K = self.k\n",
    "        X_encoder = X.view(1, -1)\n",
    "        Y_encoder = model.encoder(X_encoder)\n",
    "        \n",
    "        next_word = self.start_symbol\n",
    "        dec_input = torch.zeros(1, 0).type_as(enc_input.data)\n",
    "        dec_input = torch.cat([dec_input.detach(),torch.tensor([[next_word]],dtype=enc_input.dtype)],-1)\n",
    "        sequences = [(dec_input, 1)]\n",
    "        for _ in range(self.max_predict_length):\n",
    "            # concate next word\n",
    "            counter = 0\n",
    "            all_condidates = []\n",
    "            for (sequence, prob) in sequences:\n",
    "                dec_input = sequence\n",
    "                # run decoder and linear\n",
    "                Y_decoder = model.decoder(dec_input, Y_encoder, X_encoder)\n",
    "                word_probability = model.linear(Y_decoder)\n",
    "                word_probability = nn.Softmax(dim=-1)(word_probability.squeeze(0))\n",
    "                word_probability = word_probability[-1].squeeze(0)\n",
    "                for i in range(word_probability.size(-1)):\n",
    "                    candidate = (\n",
    "                        torch.cat([dec_input.detach(),torch.tensor([[i]],dtype=enc_input.dtype)],-1),\n",
    "                        prob * word_probability[i].item()\n",
    "                    )\n",
    "                    all_condidates.append(candidate)\n",
    "            ordered = sorted(all_condidates, key=lambda x:x[1], reverse=True)\n",
    "            sequences = ordered[:K]\n",
    "        return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "attempted-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_symbol= custom_data.tgt_vocab['S']\n",
    "stop_symbol = [custom_data.tgt_vocab['.'], custom_data.tgt_vocab['E']]\n",
    "stop_symbol = [custom_data.tgt_vocab['E']]\n",
    "max_predict_length = 6\n",
    "enc_inputs, _, _ = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "round-defensive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 0],\n",
       "         [1, 2, 3, 5, 0]]),\n",
       " 2,\n",
       " 6)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_inputs, len(enc_inputs), start_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "regional-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search = BeamSearch(model, k=5, start_symbol=start_symbol, stop_symbol=stop_symbol, \n",
    "                         max_predict_length=max_predict_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "behavioral-walker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 1, 2, 3, 4, 8, 7])\n",
      "['ich', 'mochte', 'ein', 'bier', 'P']\n",
      "['S', 'i', 'want', 'a', 'beer', '.', 'E']\n",
      "tensor([6, 1, 2, 3, 5, 8, 7])\n",
      "['ich', 'mochte', 'ein', 'cola', 'P']\n",
      "['S', 'i', 'want', 'a', 'coke', '.', 'E']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(enc_inputs)):\n",
    "    predict = beam_search.greedy_decoder(enc_inputs[i])\n",
    "    print(predict)\n",
    "    print([custom_data.src_idx2word[x.item()] for x in enc_inputs[i]])\n",
    "    print([custom_data.tgt_idx2word[x.item()] for x in predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "frequent-parcel",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "encoder() missing 1 required positional argument: 'mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-0d63a0e32b91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpredict_sequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeam_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcustom_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc_idx2word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menc_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcustom_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtgt_idx2word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredict_sequences\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-80-6eb8d93b4c71>\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mX_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mY_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_encoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mnext_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_symbol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: encoder() missing 1 required positional argument: 'mask'"
     ]
    }
   ],
   "source": [
    "for i in range(len(enc_inputs)):\n",
    "    predict_sequences = beam_search.search(enc_inputs[i])\n",
    "    print(predict_sequences)\n",
    "    print([custom_data.src_idx2word[x.item()] for x in enc_inputs[i]])\n",
    "    print([[custom_data.tgt_idx2word[x.item()] for x in seq.squeeze(0)] for (seq, _) in predict_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-fortune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-breath",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-module",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-negotiation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-mounting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
