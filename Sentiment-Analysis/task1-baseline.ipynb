{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "# 每次运行网络的时候算法和SEED是固定的，方便复现\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize='spacy', tokenizer_language='en_core_web_sm')\n",
    "LABEL = data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165,\n",
       " {'text': ['Bromwell',\n",
       "   'High',\n",
       "   'is',\n",
       "   'a',\n",
       "   'cartoon',\n",
       "   'comedy',\n",
       "   '.',\n",
       "   'It',\n",
       "   'ran',\n",
       "   'at',\n",
       "   'the',\n",
       "   'same',\n",
       "   'time',\n",
       "   'as',\n",
       "   'some',\n",
       "   'other',\n",
       "   'programs',\n",
       "   'about',\n",
       "   'school',\n",
       "   'life',\n",
       "   ',',\n",
       "   'such',\n",
       "   'as',\n",
       "   '\"',\n",
       "   'Teachers',\n",
       "   '\"',\n",
       "   '.',\n",
       "   'My',\n",
       "   '35',\n",
       "   'years',\n",
       "   'in',\n",
       "   'the',\n",
       "   'teaching',\n",
       "   'profession',\n",
       "   'lead',\n",
       "   'me',\n",
       "   'to',\n",
       "   'believe',\n",
       "   'that',\n",
       "   'Bromwell',\n",
       "   'High',\n",
       "   \"'s\",\n",
       "   'satire',\n",
       "   'is',\n",
       "   'much',\n",
       "   'closer',\n",
       "   'to',\n",
       "   'reality',\n",
       "   'than',\n",
       "   'is',\n",
       "   '\"',\n",
       "   'Teachers',\n",
       "   '\"',\n",
       "   '.',\n",
       "   'The',\n",
       "   'scramble',\n",
       "   'to',\n",
       "   'survive',\n",
       "   'financially',\n",
       "   ',',\n",
       "   'the',\n",
       "   'insightful',\n",
       "   'students',\n",
       "   'who',\n",
       "   'can',\n",
       "   'see',\n",
       "   'right',\n",
       "   'through',\n",
       "   'their',\n",
       "   'pathetic',\n",
       "   'teachers',\n",
       "   \"'\",\n",
       "   'pomp',\n",
       "   ',',\n",
       "   'the',\n",
       "   'pettiness',\n",
       "   'of',\n",
       "   'the',\n",
       "   'whole',\n",
       "   'situation',\n",
       "   ',',\n",
       "   'all',\n",
       "   'remind',\n",
       "   'me',\n",
       "   'of',\n",
       "   'the',\n",
       "   'schools',\n",
       "   'I',\n",
       "   'knew',\n",
       "   'and',\n",
       "   'their',\n",
       "   'students',\n",
       "   '.',\n",
       "   'When',\n",
       "   'I',\n",
       "   'saw',\n",
       "   'the',\n",
       "   'episode',\n",
       "   'in',\n",
       "   'which',\n",
       "   'a',\n",
       "   'student',\n",
       "   'repeatedly',\n",
       "   'tried',\n",
       "   'to',\n",
       "   'burn',\n",
       "   'down',\n",
       "   'the',\n",
       "   'school',\n",
       "   ',',\n",
       "   'I',\n",
       "   'immediately',\n",
       "   'recalled',\n",
       "   '.........',\n",
       "   'at',\n",
       "   '..........',\n",
       "   'High',\n",
       "   '.',\n",
       "   'A',\n",
       "   'classic',\n",
       "   'line',\n",
       "   ':',\n",
       "   'INSPECTOR',\n",
       "   ':',\n",
       "   'I',\n",
       "   \"'m\",\n",
       "   'here',\n",
       "   'to',\n",
       "   'sack',\n",
       "   'one',\n",
       "   'of',\n",
       "   'your',\n",
       "   'teachers',\n",
       "   '.',\n",
       "   'STUDENT',\n",
       "   ':',\n",
       "   'Welcome',\n",
       "   'to',\n",
       "   'Bromwell',\n",
       "   'High',\n",
       "   '.',\n",
       "   'I',\n",
       "   'expect',\n",
       "   'that',\n",
       "   'many',\n",
       "   'adults',\n",
       "   'of',\n",
       "   'my',\n",
       "   'age',\n",
       "   'think',\n",
       "   'that',\n",
       "   'Bromwell',\n",
       "   'High',\n",
       "   'is',\n",
       "   'far',\n",
       "   'fetched',\n",
       "   '.',\n",
       "   'What',\n",
       "   'a',\n",
       "   'pity',\n",
       "   'that',\n",
       "   'it',\n",
       "   'is',\n",
       "   \"n't\",\n",
       "   '!'],\n",
       "  'label': 'pos'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vars(train.examples[0])['text']), vars(train.examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train.split(\n",
    "    split_ratio=0.8, \n",
    "    random_state=random.seed(SEED)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5000, 25000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建vocabulary\n",
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25002, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab), len(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建迭代器\n",
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, V, E, H, O):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(V, E)\n",
    "        self.rnn = nn.RNN(E, H)\n",
    "        self.fc = nn.Linear(H, O)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.embedding(X)\n",
    "        output, hidden = self.rnn(X)\n",
    "        # hidden 是隐藏层的最后一层，也是最后一个时间步的输出\n",
    "        assert torch.equal(output[-1, :, :], hidden.squeeze(0))\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocab_length = len(TEXT.vocab)\n",
    "Embedding_dim = 100\n",
    "Hidden_dim = 256\n",
    "Output_dim = 1\n",
    "Learning_rate = 1e-3\n",
    "Epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(Vocab_length, Embedding_dim, Hidden_dim, Output_dim)\n",
    "optimizer = optim.SGD(model.parameters(), lr=Learning_rate)\n",
    "# 也可以使用crossentropyloss, 二分类任务\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    # sigmoid 转化为0~1之间的实数，相当于概率\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    model.eval()  # 取消dropout，不重新计算batch normalization\n",
    "    with torch.no_grad():  # 不计算梯度，节省内存和时间\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.79%\n",
      "\t Val. Loss: 0.694 |  Val. Acc: 49.11%\n",
      "Epoch: 02 | Epoch Time: 0m 18s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.95%\n",
      "\t Val. Loss: 0.694 |  Val. Acc: 48.73%\n",
      "Epoch: 03 | Epoch Time: 0m 18s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.97%\n",
      "\t Val. Loss: 0.694 |  Val. Acc: 48.81%\n",
      "Epoch: 04 | Epoch Time: 0m 18s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.99%\n",
      "\t Val. Loss: 0.694 |  Val. Acc: 48.99%\n",
      "Epoch: 05 | Epoch Time: 0m 18s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.48%\n",
      "\t Val. Loss: 0.694 |  Val. Acc: 48.32%\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train(\n",
    "        model, \n",
    "        train_iterator, \n",
    "        optimizer, \n",
    "        criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), './models/rnn-best-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.686 | Test Acc: 56.00%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./models/rnn-best-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
